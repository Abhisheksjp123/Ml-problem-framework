{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "source": [
    "# advance preprocessing is not applied in this NB\r\n",
    "# advance modelling is not applied in this node book\r\n",
    "# evaluation on train test split is not done in this note book"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "source": [
    "#importing pandas, numpy for preprocssing\r\n",
    "import pandas as pd\r\n",
    "import numpy as np\r\n",
    "from datetime import datetime, timedelta"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "source": [
    "#reading the test data\r\n",
    "#changes to the train data are done alongside in a seperate NB(notebook)\r\n",
    "df = pd.read_csv(\"train.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# preprocessing"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "source": [
    "# first take care of missing values, most model don't work with NaN\r\n",
    "# convert string variable to integer \r\n",
    "# use dummy variable for columns having multiple categories"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "source": [
    "df.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "   Id   Open Date        City  City Group Type  P1   P2   P3   P4  P5  ...  \\\n",
       "0   0  07/17/1999    İstanbul  Big Cities   IL   4  5.0  4.0  4.0   2  ...   \n",
       "1   1  02/14/2008      Ankara  Big Cities   FC   4  5.0  4.0  4.0   1  ...   \n",
       "2   2  03/09/2013  Diyarbakır       Other   IL   2  4.0  2.0  5.0   2  ...   \n",
       "3   3  02/02/2012       Tokat       Other   IL   6  4.5  6.0  6.0   4  ...   \n",
       "4   4  05/09/2009   Gaziantep       Other   IL   3  4.0  3.0  4.0   2  ...   \n",
       "\n",
       "   P29  P30  P31  P32  P33  P34  P35  P36  P37    revenue  \n",
       "0  3.0    5    3    4    5    5    4    3    4  5653753.0  \n",
       "1  3.0    0    0    0    0    0    0    0    0  6923131.0  \n",
       "2  3.0    0    0    0    0    0    0    0    0  2055379.0  \n",
       "3  7.5   25   12   10    6   18   12   12    6  2675511.0  \n",
       "4  3.0    5    1    3    2    3    4    3    3  4316715.0  \n",
       "\n",
       "[5 rows x 43 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Open Date</th>\n",
       "      <th>City</th>\n",
       "      <th>City Group</th>\n",
       "      <th>Type</th>\n",
       "      <th>P1</th>\n",
       "      <th>P2</th>\n",
       "      <th>P3</th>\n",
       "      <th>P4</th>\n",
       "      <th>P5</th>\n",
       "      <th>...</th>\n",
       "      <th>P29</th>\n",
       "      <th>P30</th>\n",
       "      <th>P31</th>\n",
       "      <th>P32</th>\n",
       "      <th>P33</th>\n",
       "      <th>P34</th>\n",
       "      <th>P35</th>\n",
       "      <th>P36</th>\n",
       "      <th>P37</th>\n",
       "      <th>revenue</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>07/17/1999</td>\n",
       "      <td>İstanbul</td>\n",
       "      <td>Big Cities</td>\n",
       "      <td>IL</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5653753.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>02/14/2008</td>\n",
       "      <td>Ankara</td>\n",
       "      <td>Big Cities</td>\n",
       "      <td>FC</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6923131.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>03/09/2013</td>\n",
       "      <td>Diyarbakır</td>\n",
       "      <td>Other</td>\n",
       "      <td>IL</td>\n",
       "      <td>2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2055379.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>02/02/2012</td>\n",
       "      <td>Tokat</td>\n",
       "      <td>Other</td>\n",
       "      <td>IL</td>\n",
       "      <td>6</td>\n",
       "      <td>4.5</td>\n",
       "      <td>6.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4</td>\n",
       "      <td>...</td>\n",
       "      <td>7.5</td>\n",
       "      <td>25</td>\n",
       "      <td>12</td>\n",
       "      <td>10</td>\n",
       "      <td>6</td>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "      <td>6</td>\n",
       "      <td>2675511.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>05/09/2009</td>\n",
       "      <td>Gaziantep</td>\n",
       "      <td>Other</td>\n",
       "      <td>IL</td>\n",
       "      <td>3</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>4316715.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 43 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 32
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "source": [
    "df.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(137, 43)"
      ]
     },
     "metadata": {},
     "execution_count": 33
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "source": [
    "df.isnull().sum()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Id            0\n",
       "Open Date     0\n",
       "City          0\n",
       "City Group    0\n",
       "Type          0\n",
       "P1            0\n",
       "P2            0\n",
       "P3            0\n",
       "P4            0\n",
       "P5            0\n",
       "P6            0\n",
       "P7            0\n",
       "P8            0\n",
       "P9            0\n",
       "P10           0\n",
       "P11           0\n",
       "P12           0\n",
       "P13           0\n",
       "P14           0\n",
       "P15           0\n",
       "P16           0\n",
       "P17           0\n",
       "P18           0\n",
       "P19           0\n",
       "P20           0\n",
       "P21           0\n",
       "P22           0\n",
       "P23           0\n",
       "P24           0\n",
       "P25           0\n",
       "P26           0\n",
       "P27           0\n",
       "P28           0\n",
       "P29           0\n",
       "P30           0\n",
       "P31           0\n",
       "P32           0\n",
       "P33           0\n",
       "P34           0\n",
       "P35           0\n",
       "P36           0\n",
       "P37           0\n",
       "revenue       0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 34
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "source": [
    "df[\"Type\"].value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "FC    76\n",
       "IL    60\n",
       "DT     1\n",
       "Name: Type, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 35
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "source": [
    "#converting string var to int\r\n",
    "city_type = {\"Big Cities\":1, \"Other\" :0}\r\n",
    "df[\"City Group\"] = df[\"City Group\"].map(city_type)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "source": [
    "# change the date column to date time, this will help in extracting year/month/day/date which can be used as features\r\n",
    "df[\"Open Date\"] = pd.to_datetime(df[\"Open Date\"], format='%m/%d/%Y')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "source": [
    "df[\"Open Date\"].dtype"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "dtype('<M8[ns]')"
      ]
     },
     "metadata": {},
     "execution_count": 38
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "source": [
    "# feature emgineering: as in this particulat dataset, year of opening can have significant effect on dependent variable\r\n",
    "df[\"year\"] = pd.DatetimeIndex(df[\"Open Date\"]).year"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "source": [
    "df.year.value_counts()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2011    25\n",
       "2012    18\n",
       "2009    16\n",
       "2010    15\n",
       "2008    14\n",
       "2013    12\n",
       "2006     7\n",
       "2007     7\n",
       "1999     4\n",
       "2005     4\n",
       "1998     4\n",
       "2004     3\n",
       "2014     2\n",
       "2000     2\n",
       "2002     2\n",
       "1997     1\n",
       "1996     1\n",
       "Name: year, dtype: int64"
      ]
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "source": [
    "# extracting test set which has been applied the same formatting as the train set\r\n",
    "df_test = pd.read_csv(\"processed_test.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "source": [
    "df.shape, df_test.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((137, 44), (100000, 44))"
      ]
     },
     "metadata": {},
     "execution_count": 46
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "source": [
    "df.columns, df_test.columns"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(Index(['Id', 'Open Date', 'City', 'City Group', 'Type', 'P1', 'P2', 'P3', 'P4',\n",
       "        'P5', 'P6', 'P7', 'P8', 'P9', 'P10', 'P11', 'P12', 'P13', 'P14', 'P15',\n",
       "        'P16', 'P17', 'P18', 'P19', 'P20', 'P21', 'P22', 'P23', 'P24', 'P25',\n",
       "        'P26', 'P27', 'P28', 'P29', 'P30', 'P31', 'P32', 'P33', 'P34', 'P35',\n",
       "        'P36', 'P37', 'revenue', 'year'],\n",
       "       dtype='object'),\n",
       " Index(['Id', 'Open Date', 'City', 'City Group', 'Type', 'P1', 'P2', 'P3', 'P4',\n",
       "        'P5', 'P6', 'P7', 'P8', 'P9', 'P10', 'P11', 'P12', 'P13', 'P14', 'P15',\n",
       "        'P16', 'P17', 'P18', 'P19', 'P20', 'P21', 'P22', 'P23', 'P24', 'P25',\n",
       "        'P26', 'P27', 'P28', 'P29', 'P30', 'P31', 'P32', 'P33', 'P34', 'P35',\n",
       "        'P36', 'P37', 'year', 'revenue'],\n",
       "       dtype='object'))"
      ]
     },
     "metadata": {},
     "execution_count": 47
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "source": [
    "# for some preprocessing both the datasets need to be handeled altogether\r\n",
    "# like dummy variables created int test and train will not be same because of different categories in the Type column\r\n",
    "# hence concatanating them\r\n",
    "# this cam also be done in scaling for having the same scale\r\n",
    "df2 = df.append([df_test])"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "source": [
    "df2.shape, df3.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((100137, 44), (100137, 109))"
      ]
     },
     "metadata": {},
     "execution_count": 62
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "source": [
    "# function for dummy variable treatment\r\n",
    "def dummy_handle(dfX, col):\r\n",
    "    temp = pd.DataFrame()\r\n",
    "    for c in col:\r\n",
    "        dummy_df = pd.get_dummies(dfX[c],drop_first=True)\r\n",
    "        temp = pd.concat([temp,dummy_df],axis = 1)\r\n",
    "    dfX = pd.concat([dfX,temp], axis = 1)\r\n",
    "    return dfX\r\n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "source": [
    "categ_col = [\"City\", \"Type\"]\r\n",
    "# categ_col = [\"City\"]\r\n",
    "df3 = dummy_handle(df2, categ_col)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "source": [
    "# dropping columns whose dummy variable is already being made\r\n",
    "# dropping columns which will provide no information to the model\r\n",
    "df3.drop(categ_col,axis = 1, inplace=True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "df3.drop([\"Id\", \"Open Date\"],axis = 1, inplace = True)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "df3.columns"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Index(['City Group', 'P1', 'P2', 'P3', 'P4', 'P5', 'P6', 'P7', 'P8', 'P9',\n",
       "       ...\n",
       "       'Zonguldak', 'Çanakkale', 'Çankırı', 'Çorum', 'İstanbul', 'İzmir',\n",
       "       'Şanlıurfa', 'FC', 'IL', 'MB'],\n",
       "      dtype='object', length=105)"
      ]
     },
     "metadata": {},
     "execution_count": 86
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Modelling"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "#splitting the training and the test set for modelling\r\n",
    "df_train = df3.iloc[0:137]\r\n",
    "df_pred = df3.iloc[137:]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "#splitting the sependent and independent variables in the taining data for modelling\r\n",
    "import xgboost as xgb\r\n",
    "X = df_train.drop([\"revenue\"],axis = 1)\r\n",
    "y = df_train[\"revenue\"]"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "# fitting the regressor on the training data\r\n",
    "xgbReg = xgb.XGBRFRegressor()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "source": [
    "xgbReg.fit(X,y)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "XGBRFRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "               colsample_bytree=1, gamma=0, gpu_id=-1, importance_type='gain',\n",
       "               interaction_constraints='', max_delta_step=0, max_depth=6,\n",
       "               min_child_weight=1, missing=nan, monotone_constraints='()',\n",
       "               n_estimators=100, n_jobs=8, num_parallel_tree=100,\n",
       "               objective='reg:squarederror', random_state=0, reg_alpha=0,\n",
       "               scale_pos_weight=1, tree_method='exact', validate_parameters=1,\n",
       "               verbosity=None)"
      ]
     },
     "metadata": {},
     "execution_count": 90
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "# predicting the results for test independent variable\r\n",
    "y_pred = xgbReg.predict(df_pred.drop([\"revenue\"],axis = 1))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "source": [
    "y_pred.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(100000,)"
      ]
     },
     "metadata": {},
     "execution_count": 93
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "# saving the result in whatever format needed\r\n",
    "sub = pd.read_csv(\"sampleSubmission.csv\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "source": [
    "sub.Prediction = y_pred"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "sub.shape,sub.head()"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "((100000, 2),\n",
       "    Id  Prediction\n",
       " 0   0   3842737.0\n",
       " 1   1   3448579.0\n",
       " 2   2   3691910.5\n",
       " 3   3   3739250.5\n",
       " 4   4   4374149.5)"
      ]
     },
     "metadata": {},
     "execution_count": 98
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "source": [
    "# this result can be summited for initial understang of accuracy on the test data(which is hidden from us in most cases)\r\n",
    "sub.to_csv(\"sampleSubmission1.csv\", index = False)"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.3",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.3 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "17a305feab8abe6b6525719ad64b1ef90d713ac6d3592802a3734a4773c9b918"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}